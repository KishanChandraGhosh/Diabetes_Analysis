# -*- coding: utf-8 -*-
"""diabetes_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qfzBJRADq93QNmgfVIkUtM0vWuhbxtPh

#Step by step guide

* Load data
* Replace 0s â†’ NaN
* Fill NaN with mean
* Scale data
* Split into train/test
* Train model (fit)
* Test model (predict)
* Evaluate accuracy
"""

import pandas as pd
import numpy as np

"""#Load dataset"""

df = pd.read_csv("diabetes.csv")

"""#Replace invalid values"""

# Columns where 0 is invalid
cols_with_zero = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]

# Replace 0 with NaN in those columns
df[cols_with_zero] = df[cols_with_zero].replace(0, np.nan)

# Replace NaN with the column mean
for col in cols_with_zero:
    df[col] = df[col].fillna(np.mean(df[col]))

df.isnull().sum()

"""#Preprocessing"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_features = scaler.fit_transform(df.drop("Outcome", axis=1))
df_scaled = pd.DataFrame(scaled_features, columns=df.columns[:-1])
df_scaled["Outcome"] = df["Outcome"].values
print(df_scaled)

from sklearn.model_selection import train_test_split

X = df_scaled.drop("Outcome", axis=1)
y = df_scaled["Outcome"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(X_train)
print(X_test)
print(y_train)
print(y_test)
#print(y)

print(df_scaled.isnull().sum())   # Should show all 0s
print(df_scaled.describe())       # Check distribution after scaling

"""#Train the model"""

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()

model.fit(X_train, y_train)
y_pred = model.predict(X_test)

"""#Check accuracy"""

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

"""#Using Random Forest & KNN Classifier (Optional)"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

rf = RandomForestClassifier()
rf.fit(X_train, y_train)
print("Random Forest Accuracy:", rf.score(X_test, y_test))

"""#How well the model predicts diabetic vs non-diabetic cases."""

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""#Which features (like Glucose, BMI, Age, etc.) affect the prediction most."""

import pandas as pd

feature_importances = pd.Series(rf.feature_importances_, index=X.columns)
feature_importances.nlargest(10).plot(kind='barh')
plt.title("Top 10 Important Features (Random Forest)")
plt.show()

"""#Compare actual vs predicted"""

plt.figure(figsize=(6,4))
sns.countplot(x=y_test, label='Actual')
sns.countplot(x=y_pred, label='Predicted', color='orange')
plt.legend()
plt.title("Actual vs Predicted Outcome")
plt.show()

"""#Accuracy comparison of models

If trained using Logistic Regression, Random Forest, and KNN, compare them:
"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()
knn.fit(X_train, y_train)

models = {
    "Logistic Regression": model.score(X_test, y_test),
    "Random Forest": rf.score(X_test, y_test),
    "KNN": knn.score(X_test, y_test)
}

plt.bar(models.keys(), models.values())
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.show()